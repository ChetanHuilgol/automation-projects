{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from selenium import webdriver\r\n",
    "from bs4 import BeautifulSoup"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "def get_url(search_item, page):\r\n",
    "    \"\"\"Search the item using the url.\"\"\"\r\n",
    "\r\n",
    "    init_url = \"https://www.flipkart.com/search?q={}&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\r\n",
    "    search_item = search_item.replace(\" \", \"+\")\r\n",
    "    final_url = init_url.format(search_item)\r\n",
    "    final_url = final_url + \"&page={}\"\r\n",
    "    return final_url.format(page)\r\n",
    "\r\n",
    "def extractRow(item):\r\n",
    "    \"\"\"Extract details of each row of Flipkart Product.\"\"\"\r\n",
    "\r\n",
    "    title = item.find('div', attrs={'class': '_4rR01T'}).text\r\n",
    "\r\n",
    "    url = \"https://www.flipkart.com/\" + item.get('href')\r\n",
    "\r\n",
    "    try:\r\n",
    "        price = item.find('div', attrs={'class': '_30jeq3 _1_WHN1'}).text.replace('â‚¹', 'Rs.')\r\n",
    "    except AttributeError:\r\n",
    "        price = ''\r\n",
    "\r\n",
    "    try:\r\n",
    "        ratings = item.find('div', attrs={'class': '_3LWZlK'}).text\r\n",
    "    except AttributeError:\r\n",
    "        ratings = ''\r\n",
    "\r\n",
    "    try:\r\n",
    "        rating_reviews = result.find('span', attrs={'class': '_2_R_DZ'}).text.split(' ')\r\n",
    "        total_ratings = rating_reviews[0]\r\n",
    "        total_reviews = rating_reviews[2]\r\n",
    "    except AttributeError:\r\n",
    "        total_ratings = ''\r\n",
    "        total_reviews = ''\r\n",
    "\r\n",
    "    return (title, price, ratings, total_ratings, total_reviews, url)\r\n",
    "\r\n",
    "records = list()\r\n",
    "\r\n",
    "def main(search):\r\n",
    "    \"\"\"Executes the main program.\"\"\"\r\n",
    "\r\n",
    "    # Initialize the Chrome driver\r\n",
    "    driver = webdriver.Chrome(\"chromedriver\")\r\n",
    "\r\n",
    "    record = list()\r\n",
    "\r\n",
    "    for page in range(1, 21):\r\n",
    "        driver.get(get_url(search, page))\r\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\r\n",
    "        results = soup.findAll('a', href=True, attrs={'class':'_1fQZEK'})\r\n",
    "\r\n",
    "        for result in results:\r\n",
    "            record = extractRow(result)\r\n",
    "\r\n",
    "            if record:\r\n",
    "                records.append(record)\r\n",
    "\r\n",
    "    driver.close()\r\n",
    "\r\n",
    "    # # Saving file to a CSV\r\n",
    "    data = pd.DataFrame(data=records, columns=['Title', 'Price', 'Ratings', 'Total Ratings', 'Total Reviews', 'URL'])\r\n",
    "    data.to_csv('results.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Search and get the data associated with the product\r\n",
    "search = input(\"Enter the Product:\")\r\n",
    "main(search=search)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "23263b619eede791ee76531faea33d0ac3cfe2e28e54d2f570a826170ba9147e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}